{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IJCNN 2021 Demo Page\n",
    "This demo page is for the paper __Revisiting Onsets and Frames Model with Additive Attention__. High resolution figures and the audio samples for the transcription results can be found here. Source code for the paper is available at https://github.com/KinWaiCheuk/IJCNN2021.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>audio {width:200px}; td {vertical-align: middle}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "table = \"<style>audio {width:200px}; td {vertical-align: middle}</style>\"\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Archetecture\n",
    "Left: Onsets and Frames model with an additive attention mechanism<br/>\n",
    "Right: Linear model with an additive attention mechanism\n",
    "\n",
    "For Onsets and Frames model, the attention mechanism attends to only one of the three features: $\\boldsymbol{x_{\\text{spec}}}$ or $\\hat{\\boldsymbol{y}}_{\\text{onset}}$ or $\\boldsymbol{\\hat{y}_{\\text{feat}}}$\n",
    "![](demo/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription Results\n",
    "The transcription results corresponding to the four sample spectrograms above are shown here. Piano rolls generated by the model is converted to midi files, and the WAV files are rendered from the midi files using [Garritan Personal Orchestra](https://www.garritan.com/products/personal-orchestra-5/): Concert D Grand Piano\n",
    "\n",
    "### Original Audio\n",
    "\n",
    "Ground Truth 1: <audio src=\"demo/Audio/label1.wav\" controls>alternative text</audio><br/>\n",
    "Ground Truth 2: <audio src=\"demo/Audio/label2.wav\" controls>alternative text</audio><br/>\n",
    "Ground Truth 3: <audio src=\"demo/Audio/label3.wav\" controls>alternative text</audio><br/>\n",
    "Ground Truth 4: <audio src=\"demo/Audio/label4.wav\" controls>alternative text</audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onsets & Frames Model\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/ Everything</b></td>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/o BiLSTM</b></td> \n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/o Inference</b></td>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/o $F_{\\text{onset}}$</b></td>\n",
    " </tr>\n",
    " <tr>\n",
    "    <td>Spec1: <audio src=\"demo/Original_model/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec2: <audio src=\"demo/Original_model/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec3: <audio src=\"demo/Original_model/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec4: <audio src=\"demo/Original_model/4_piano.wav\" controls>alternative text</audio>\n",
    "    </td>\n",
    "    <td><audio src=\"demo/No_LSTM/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_LSTM/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_LSTM/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_LSTM/4_piano.wav\" controls>alternative text</audio>\n",
    "    </td>     \n",
    "    <td><audio src=\"demo/Original_model_no_inference/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Original_model_no_inference/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Original_model_no_inference/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Original_model_no_inference/4_piano.wav\" controls>alternative text</audio>\n",
    "     </td>\n",
    "    <td><audio src=\"demo/No_Onset_stack/1_piano.wav\" controls>sdasd text</audio><br/>\n",
    "        <audio src=\"demo/No_Onset_stack/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_Onset_stack/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_Onset_stack/4_piano.wav\" controls>alternative text</audio>\n",
    "     </td>     \n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onsets & Frames Model with Additive Attention\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/ Everything</b></td>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/o BiLSTM</b></td> \n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/o Inference</b></td>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">w/o $F_{\\text{onset}}$</b></td>\n",
    " </tr>\n",
    " <tr>\n",
    "    <td>Spec1: <audio src=\"demo/OnsetsFrames_attn/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec2: <audio src=\"demo/OnsetsFrames_attn/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec3: <audio src=\"demo/OnsetsFrames_attn/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec4: <audio src=\"demo/OnsetsFrames_attn/4_piano.wav\" controls>alternative text</audio>\n",
    "    </td>\n",
    "    <td><audio src=\"demo/No_LSTM_attn/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_LSTM_attn/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_LSTM_attn/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/No_LSTM_attn/4_piano.wav\" controls>alternative text</audio>\n",
    "    </td>     \n",
    "    <td><audio src=\"demo/OnsetsFrames_attn_no_inference/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/OnsetsFrames_attn_no_inference/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/OnsetsFrames_attn_no_inference/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/OnsetsFrames_attn_no_inference/4_piano.wav\" controls>alternative text</audio>\n",
    "     </td>\n",
    "    <td><audio src=\"demo/No_Onset_stack_attn/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "    <audio src=\"demo/No_Onset_stack_attn/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "    <audio src=\"demo/No_Onset_stack_attn/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "    <audio src=\"demo/No_Onset_stack_attn/4_piano.wav\" controls>alternative text</audio>\n",
    "     </td>     \n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">$D=5$ w/ inference</b></td>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">$D=5$ w/o inference</b></td> \n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">$D=0$ w/ inference</b></td>\n",
    "    <td style=\"text-align: left\"><b style=\"font-size:14px\">$D=0$ w/o inference</b></td>\n",
    " </tr>\n",
    " <tr>\n",
    "    <td>Spec1: <audio src=\"demo/Linear_attn_5/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec2: <audio src=\"demo/Linear_attn_5/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec3: <audio src=\"demo/Linear_attn_5/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "Spec4: <audio src=\"demo/Linear_attn_5/4_piano.wav\" controls>alternative text</audio>\n",
    "    </td>\n",
    "    <td><audio src=\"demo/Linear_attn_5_no_inference/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Linear_attn_5_no_inference/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Linear_attn_5_no_inference/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Linear_attn_5_no_inference/4_piano.wav\" controls>alternative text</audio>\n",
    "    </td>     \n",
    "    <td><audio src=\"demo/Linear_D0/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Linear_D0/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Linear_D0/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "        <audio src=\"demo/Linear_D0/4_piano.wav\" controls>alternative text</audio>\n",
    "     </td>\n",
    "    <td><audio src=\"demo/Linear_D0_no_inference/1_piano.wav\" controls>alternative text</audio><br/>\n",
    "    <audio src=\"demo/Linear_D0_no_inference/2_piano.wav\" controls>alternative text</audio><br/>\n",
    "    <audio src=\"demo/Linear_D0_no_inference/3_piano.wav\" controls>alternative text</audio><br/>\n",
    "    <audio src=\"demo/Linear_D0_no_inference/4_piano.wav\" controls>alternative text</audio>\n",
    "     </td>     \n",
    " </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Maps\n",
    "\n",
    "### Onsets and Frames Model with Attention D=30\n",
    "\n",
    "This is Figure 2 in the paper. Right click and view each image in full resolution in the new tab. \n",
    "\n",
    "![](demo/OnsetsFrames_attn/spec_map.png)\n",
    "![](demo/OnsetsFrames_attn/onset_map.png)\n",
    "![](demo/OnsetsFrames_attn/feat_map.png)\n",
    "\n",
    "Row 1: Attedning on $\\boldsymbol{x_{\\text{spec}}} \\in [0,1]^{T\\times N}$<br/>\n",
    "Row 2: Attedning on $\\boldsymbol{\\hat{y}_{\\text{onset}}} \\in [0,1]^{T\\times 88}$<br/>\n",
    "Row 3: Attedning on $\\boldsymbol{\\hat{y}_{\\text{feat}}} \\in [0,1]^{T\\times 88}$\n",
    "\n",
    "### Onsets and Frames Model with Varying Attention Size\n",
    "From top row to bottom row: <b> D=60, D=30, D=20, D=5 </b>\n",
    "![](demo/OnsetsFrames_attn/spec_map_D60.png) \n",
    "![](demo/OnsetsFrames_attn/spec_map.png)\n",
    "![](demo/OnsetsFrames_attn/spec_map_D20.png)\n",
    "![](demo/OnsetsFrames_attn/spec_map_D05.png) \n",
    "\n",
    "### Linear Model with Varying Attention Size\n",
    "From top row to bottom row: <b> D=60, D=30, D=20, D=5 </b>\n",
    "![](demo/Linear/D30.png) \n",
    "![](demo/Linear/D20.png)\n",
    "![](demo/Linear/D10.png)\n",
    "![](demo/Linear/D05.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
